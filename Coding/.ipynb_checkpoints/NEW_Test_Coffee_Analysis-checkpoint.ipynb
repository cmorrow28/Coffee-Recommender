{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67abe3d4-b936-4ab9-9e08-d231aef1cc60",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# So, How Do You Like *Your* Coffee?"
=======
    "# So, How Do You Like *Your* Coffee?\n",
    "\n",
    "A machine learning project built by Jesslyn Lengkong, Cayley Morrow and Dominique Spencer\n",
    "\n",
    "---"
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "ab1a2e95-c69b-4e72-81c3-2e2348129a77",
   "metadata": {},
   "source": [
    "## Read in csv file"
=======
   "id": "c6c07748-17d5-491f-a7b8-b512801d6847",
   "metadata": {},
   "source": [
    "### Initial steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9b211-4613-4858-8539-22323c530052",
   "metadata": {},
   "source": [
    "##### Import dependencies and read in csv file."
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8210a-ef78-477c-bf4e-bd21257e3dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "import pycountry\n",
    "import re\n",
    "from sqlalchemy import create_engine, text, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582084e1-4143-4a98-be80-204631773497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the csv into a Pandas DataFrame\n",
    "coffee_df = pd.read_csv('../Resources/coffee.csv', encoding='utf-8')\n",
    "coffee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c9a5c-a316-4cdf-9c41-64927cbdde93",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a brief summary of DataFrame\n",
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "e491e857-caff-4cc8-b58b-4995bcc869d6",
   "metadata": {},
   "source": [
    "## Initial general clean"
=======
   "id": "be876df9-f0ed-4819-98be-4cb2ea752746",
   "metadata": {},
   "source": [
    "##### Drop unwanted columns and clean text values using a regex pattern."
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c3244-2604-4d64-b27c-9e704351023c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns \n",
    "coffee_df = coffee_df.drop(columns=['all_text', 'est_price', 'review_date', 'agtron', 'location', 'with_milk', 'desc_3', 'desc_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca20ad-5b73-4a82-aa64-e3535af2e0c9",
   "metadata": {},
   "source": [
    "##### Clean 'roaster','desc_1', 'desc_2' columns to neaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c0397-826d-4aa4-8949-7af82417bba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the columns to clean with regex\n",
    "columns_to_clean = ['roaster','desc_1', 'desc_2']\n",
    "\n",
    "# Define a regex pattern to match special characters\n",
    "special_characters_pattern = r'[^a-zA-Z0-9\\s,.-Ã©\"]'\n",
    "\n",
    "# Clean chosen columns\n",
    "for column in columns_to_clean:\n",
    "    coffee_df[column] = coffee_df[column].str.replace(special_characters_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb8434-65ad-453e-8744-06ca6b01863d",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Work with the 'origin' column"
=======
    "### Work with the 'origin' column:"
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884ef2b-529a-417c-9fec-91bf1b56f276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get details about 'origin' column\n",
    "coffee_df['origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83fa8a-4728-427c-995e-08f12423ea07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the dot at the end of string in 'origin' column\n",
    "coffee_df['origin'] = coffee_df['origin'].str.rstrip('.')\n",
    "coffee_df['origin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "d90264f1-8af7-4b5c-91d7-de145bbc28f3",
   "metadata": {},
   "source": [
    "##### Delete all rows with different iterations of 'not disclosed' from 'origin' column"
=======
   "id": "4a3a12ff-4a07-40db-8013-f8dd22d6d84e",
   "metadata": {},
   "source": [
    "##### Delete all rows with different iterations of 'not disclosed' from 'origin' column."
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f6617-d543-49b7-9325-d8997f0f3a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a regex pattern\n",
    "pattern = re.compile(r'not\\s*disclosed', flags=re.IGNORECASE)\n",
    "\n",
    "# Apply this to 'origin' column\n",
    "coffee_df = coffee_df[~coffee_df['origin'].str.contains(pattern, na=False) | coffee_df['origin'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbbf0d-749e-41f1-b133-26841180d0a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete rows with NaN values from 'origin' column\n",
    "coffee_df = coffee_df.dropna(subset=['origin'])"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "d56116c4-e1ac-4475-8c38-cbf79ff452da",
   "metadata": {},
   "source": [
    "##### Create new column with specific 'country of origin' values"
=======
   "id": "77e70f13-cb71-44ca-977b-7637cdac8bb2",
   "metadata": {},
   "source": [
    "##### Create a new column with specific 'country of origin' values."
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ac01a-1deb-47a0-8056-cd83b12778b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the 'origin' column \n",
    "old_origin_column = 'origin'\n",
    "\n",
    "# Create a new column to store the split result\n",
    "new_origin_column = 'country_of_origin'\n",
    "\n",
    "# Function to split the last word and add it to the new column\n",
    "def split_last_word_except_semicolon(text):\n",
    "    if pd.isna(text):  # Check if the value is NaN\n",
    "        return ''\n",
    "    words = re.split(r'\\s*;\\s*|\\s+', text)\n",
    "    return words[-1]\n",
    "\n",
    "# Apply the function to create a new column\n",
    "coffee_df['country_of_origin'] = coffee_df['origin'].apply(split_last_word_except_semicolon)\n",
    "\n",
    "# Check the updated DataFrame\n",
    "coffee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56753ba-6e1b-498d-aab9-a1b2da496a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check values\n",
    "coffee_df['country_of_origin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "37174f70-6064-4003-807f-40e04f9be23b",
   "metadata": {},
   "source": [
    "##### Remove all data that is not significant enough for machine learning model (ie - less than 12 instances)"
=======
   "id": "a7f1b326-17a9-4816-8e12-d8976abaa36c",
   "metadata": {},
   "source": [
    "##### Remove all rows where there are 12 or fewer value counts."
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5de7e-25df-4011-beb2-c2ba59f8e6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the datatype of the specified column to string\n",
    "coffee_df['country_of_origin'] = coffee_df['country_of_origin'].astype(str)\n",
    "\n",
    "# Set the cutoff value\n",
    "cutoff = 12\n",
    "\n",
    "# Create a variable for rows to keep\n",
    "keep_rows = coffee_df['country_of_origin'].map(coffee_df['country_of_origin'].value_counts()) >= cutoff\n",
    "\n",
    "# Keep only the rows where the count is at least the cutoff\n",
    "coffee_df = coffee_df[keep_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d5803-5e6d-4e7a-a0b8-8bb99cbe1730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Check dataframe status\n",
=======
    "# Get a refreshed summary of DataFrame\n",
>>>>>>> DMS
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "c6611c82-8fff-48ec-8a55-5e517e624670",
   "metadata": {},
   "source": [
    "##### Extra Dataframe cleaning"
=======
   "id": "8004002d-81b1-4e77-ab10-fd8b84db754e",
   "metadata": {},
   "source": [
    "##### Drop all rows with blank values, and general country name 'Africa'."
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a09d0-b3f2-4a14-b195-d7af4716e8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the rows with blank values from the original DataFrame\n",
    "rows_with_blank_values = coffee_df[coffee_df['country_of_origin'].isna() | (coffee_df['country_of_origin'] == '')]\n",
    "\n",
    "if not rows_with_blank_values.empty:\n",
    "    coffee_df.drop(rows_with_blank_values.index, inplace=True)\n",
    "    \n",
    "# Drop all rows containing 'Africa' as a country of origin\n",
    "string_to_drop = 'Africa'\n",
    "coffee_df = coffee_df[~coffee_df['country_of_origin'].str.contains(string_to_drop, case=False, na=False)]\n",
    "\n",
    "# Check the updated DataFrame\n",
    "coffee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d7e9f-f63d-4e26-9386-f1443d43d724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop original 'origin' column\n",
    "coffee_df = coffee_df.drop(columns='origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81a4bdd-867a-44a4-9a30-59d74d7d57f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coffee_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check total values of new column 'country_of_origin'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m coffee_df\u001b[38;5;241m.\u001b[39mcountry_of_origin\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'coffee_df' is not defined"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Check values\n",
=======
    "# Check total values of new column 'country_of_origin'\n",
>>>>>>> DMS
    "coffee_df.country_of_origin.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89cad5a-791c-42b4-b9f8-34ec5432705a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Check Dataframe status\n",
=======
    "# Get a refreshed summary of DataFrame\n",
>>>>>>> DMS
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cfe660-9584-4c7e-b16f-3b789a78faff",
   "metadata": {},
   "source": [
    "### Get latitude and longitude for countries_of_origin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c6fe4-a0c4-4333-bcff-f5312c8589df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check unique values from the 'country_of_origin' column\n",
    "coffee_df['country_of_origin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "56fe415b-4b70-45ed-a31a-fa18f5745a62",
   "metadata": {},
   "source": [
    "##### Change country names to match country names in pycountry library"
=======
   "id": "ca9df507-ff6a-4166-b434-9576d5e99e67",
   "metadata": {},
   "source": [
    "##### Change country names to match country names in pycountry library."
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d40bd66-1462-4bf7-aa46-7fbd324ad06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a dictionary of old and new values\n",
    "values_to_update = {'America': 'United States',\n",
    "                    'Hawaii': 'United States', \n",
    "                    'Democratic_Republic_of_Congo' : 'Congo, The Democratic Republic of the', \n",
    "                    'Salvador': 'El Salvador', \n",
    "                    'Costa_Rica': 'Costa Rica', \n",
    "                    'Tanzania': 'Tanzania, United Republic of', \n",
    "                    'Papua_New_Guinea': 'Papua New Guinea', \n",
    "                    'Bolivia': 'Bolivia, Plurinational State of', \n",
    "                    'Sumatra': 'Indonesia', \n",
    "                    'Taiwan': 'China'\n",
    "                   }\n",
    "\n",
    "# Create a mask for rows that need updating\n",
    "update_mask = coffee_df['country_of_origin'].isin(values_to_update.keys())\n",
    "\n",
    "# Update the values in the 'country_of_origin' column\n",
<<<<<<< HEAD
    "coffee_df.loc[update_mask, 'country_of_origin'] = coffee_df.loc[update_mask, 'country_of_origin'].replace(values_to_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f756a-508f-45b4-9d13-23751f55bf05",
   "metadata": {},
   "source": [
    "##### Minimise dataframe so pycountry function can run effectively on far fewer rows"
=======
    "coffee_df.loc[update_mask, 'country_of_origin'] = coffee_df.loc[update_mask, 'country_of_origin'].replace(values_to_update)\n",
    "\n",
    "# Check the updated DataFrame\n",
    "coffee_df.head()"
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29af82-3f38-4821-a0fa-86592f8c57a2",
   "metadata": {},
   "source": [
    "##### Minimise dataframe to only unique values for pycountry function efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ffa1e-349d-4464-a1a1-179be2e40c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame of the 'country_of_origin' column for getting lat and lon\n",
    "coffee_countries = coffee_df[['country_of_origin']].copy()\n",
    "\n",
    "# Extract unique values from the 'Category' column\n",
    "unique_categories = coffee_countries['country_of_origin'].unique()\n",
    "\n",
    "# Create a new DataFrame with unique values\n",
    "unique_df = pd.DataFrame({'country_of_origin': unique_categories})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2a710-5361-4d50-9b90-17144d7b48ed",
   "metadata": {},
   "source": [
    "##### Function to initialise pycountry and get lat and lon coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883e1b0-7047-4f84-9f01-3c0e3efb19b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get coordinates using pycountry library\n",
    "def get_coordinates(country):\n",
    "    try:\n",
    "        country_obj = pycountry.countries.get(name=country)\n",
    "        geolocator = Nominatim(user_agent=\"coffee_countries\", timeout=20)\n",
    "        location = geolocator.geocode(country_obj.name)\n",
    "        return location.latitude, location.longitude\n",
    "    except AttributeError:\n",
    "        return None, None\n",
    "\n",
<<<<<<< HEAD
    "unique_df[['latitude', 'longitude']] = unique_df['country_of_origin'].apply(get_coordinates).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef5278-3a49-455e-ad76-b7a7871103cd",
   "metadata": {},
   "source": [
    "##### Merge minimised dataframe with original dataframe to add coordinates to each row"
=======
    "# Apply function to new Dataframe    \n",
    "unique_df[['latitude', 'longitude']] = unique_df['country_of_origin'].apply(get_coordinates).apply(pd.Series)\n",
    "\n",
    "# Check the updated DataFrame\n",
    "unique_df"
>>>>>>> DMS
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fee08f-f77d-4d73-a285-7416b95f01ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrames based on the common column\n",
    "new_coffee_df = pd.merge(coffee_df, unique_df, on='country_of_origin', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f027543-218e-4bec-be62-8abf773ce827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Check merge worked\n",
=======
    "# Check the updated DataFrame\n",
>>>>>>> DMS
    "new_coffee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729249d4-d49f-4a20-b868-50488c1ed86a",
   "metadata": {},
   "source": [
    "### Complete final cleaning and exporting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f7043-5e56-4337-8990-c810ac778de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Check Dataframe status\n",
=======
    "# Check the updated DataFrame value counts\n",
>>>>>>> DMS
    "new_coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80aa47-2090-4cbf-ae66-113cd831a627",
   "metadata": {},
   "source": [
    "## Final cleaning steps and export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b228ed-9c58-494f-af35-7bfdc2e09118",
   "metadata": {},
   "source": [
    "#### Reorder columns in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "a5ae328f-bfdd-4920-a31d-3f6aca255462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display new Dataframe columns\n",
    "new_coffee_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> DMS
   "id": "4492fba5-f3b7-4b18-8c2f-3a1722f8c795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# New column order\n",
=======
    "# Reorder columns\n",
>>>>>>> DMS
    "coffee_df = new_coffee_df[['slug', 'name', 'roaster', 'roast', 'country_of_origin', 'desc_1', 'desc_2', 'latitude', 'longitude', 'rating',\n",
    "                       'aroma', 'acid', 'body', 'flavor', 'aftertaste',\n",
    "                       'region_africa_arabia', 'region_caribbean', 'region_central_america', 'region_hawaii', 'region_asia_pacific', 'region_south_america', \n",
    "                       'type_espresso', 'type_organic', 'type_fair_trade', 'type_decaffeinated', 'type_pod_capsule', 'type_blend', 'type_estate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "096c8634-ac10-488a-b042-1aaf341c21bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check Dataframe status\n",
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> DMS
   "id": "f33d7adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop all rows with null values \n",
    "coffee_df = coffee_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fd7f1-49f4-41db-a7a7-5ac0e5599519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Check Dataframe status\n",
=======
    "# Review the updated DataFrame after all previous changes\n",
>>>>>>> DMS
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e11e775-a2a0-4394-8611-20ab1f469613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coffee_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Export Dataframe as new csv file to Resources folder\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m coffee_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Resources/NEW_coffee_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'coffee_df' is not defined"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Export Dataframe as new csv file to Resources folder\n",
=======
    "# Save Dataframe to Resources folder\n",
>>>>>>> DMS
    "coffee_df.to_csv('../Resources/NEW_coffee_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a01e6e-88f3-4612-bc71-2c66870d5d8c",
   "metadata": {},
   "source": [
    "### Create SQL database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096a518-a072-41ff-a0d8-094d4139b97d",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Create engine path\n",
=======
    "# Define engine path\n",
>>>>>>> DMS
    "engine = create_engine('sqlite:///Data_Engineering.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b869c7e-4a84-4a7a-9dc2-9092471d3b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the existing table and create a new one with the desired primary key\n",
    "with engine.connect() as con:\n",
    "    con.execute(text('''\n",
    "        CREATE TABLE IF NOT EXISTS coffee_data (\n",
    "            \"slug\" VARCHAR, \n",
    "            \"name\" VARCHAR, \n",
    "            \"roaster\" VARCHAR, \n",
    "            \"roast\" VARCHAR, \n",
    "            \"country_of_origin\" VARCHAR, \n",
    "            \"desc_1\" VARCHAR, \n",
    "            \"desc_2\" VARCHAR,\n",
    "            \"latitude\" FLOAT,\n",
    "            \"longitude\" FLOAT,\n",
    "            \"rating\" INTEGER,\n",
    "            \"aroma\" FLOAT, \n",
    "            \"acid\" FLOAT, \n",
    "            \"body\" FLOAT, \n",
    "            \"flavor\" FLOAT, \n",
    "            \"aftertaste\" FLOAT,\n",
    "            \"region_africa_arabia\" INTEGER, \n",
    "            \"region_caribbean\" INTEGER, \n",
    "            \"region_central_america\" INTEGER, \n",
    "            \"region_hawaii\" INTEGER, \n",
    "            \"region_asia_pacific\" INTEGER, \n",
    "            \"region_south_america\" INTEGER, \n",
    "            \"type_espresso\" INTEGER, \n",
    "            \"type_organic\" INTEGER, \n",
    "            \"type_fair_trade\" INTEGER, \n",
    "            \"type_decaffeinated\" INTEGER, \n",
    "            \"type_pod_capsule\" INTEGER, \n",
    "            \"type_blend\" INTEGER, \n",
    "            \"type_estate\" INTEGER,\n",
    "            PRIMARY KEY (\"slug\")\n",
    "        )\n",
    "    '''))\n",
    "\n",
    "# Output to the database \n",
    "coffee_df.to_sql(name='coffee_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02421a-4c4d-4470-be63-74c9f9ce77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection\n",
    "connection = engine.connect()\n",
    "\n",
    "# Create an Inspector and get the table names\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "# Print the table names and some sample data\n",
    "for table_name in table_names:\n",
    "    print(f\"Table: {table_name}\")\n",
    "\n",
    "    # Use text() to create a SQL expression\n",
    "    query = text(f\"SELECT * FROM {table_name} LIMIT 5\")\n",
    "    sample_data = connection.execute(query).fetchall()\n",
    "\n",
    "    print(\"Sample Data:\")\n",
    "    for row in sample_data:\n",
    "        print(row)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f03eec-2dd8-489b-b448-eb782db648cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c5e33-072c-40c7-8b5c-a4da281749ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib  \n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.decomposition import PCA\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import streamlit as st "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9575764-b7e0-4623-a8cf-d2ea2a3be564",
   "metadata": {},
   "source": [
    "# Load dataframe and reassess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d8a8f-a75a-4588-b7d4-34d5453f1541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Database Setup\n",
    "engine = create_engine(\"sqlite:///Coding/Data_Engineering.db\")\n",
    "\n",
    "# Reflect the tables\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "coffee_data = metadata.tables['coffee_data']\n",
    "\n",
    "# Fetch data from the database\n",
    "conn = engine.connect()\n",
    "result = conn.execute(coffee_data.select()).fetchall()\n",
    "conn.close()\n",
    "\n",
    "# Convert each row to a dictionary\n",
    "data = [dict(row._asdict()) for row in result]\n",
    "\n",
    "# Create a DataFrame\n",
    "coffee_data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e2702-12d0-47fb-97f1-5c271a82008e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check database has been loaded \n",
    "coffee_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d193b0c-88c1-4bdf-a2bd-c3eb7f846a19",
   "metadata": {},
   "source": [
    "## Remove null values for modelling and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9192ae-228e-4d5e-adfd-28eb5c497291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create features and target\n",
    "coffee_data_df_features = coffee_data_df[['aroma','body','flavor','acid','aftertaste']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec85893-26e2-422a-b5aa-609e5ae62bc7",
   "metadata": {},
   "source": [
    "# Elbow Curve review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a79d3-3895-41e6-8e68-88ce6299cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering\n",
    "features = ['aroma', 'flavor', 'acid', 'body', 'aftertaste'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921eaa0-6832-4664-967b-364aebc4256a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate mean, median, standard deviation, and range for each feature\n",
    "summary_stats = coffee_data_df_features[features].describe().transpose()\n",
    "\n",
    "# Display the summary statistics\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45d225-bd2a-49b1-ad69-ebedeea0e583",
   "metadata": {},
   "source": [
    "- <b> Aroma: </b> Interpretation: The average aroma rating is around 8.47, with a moderate level of variability (standard deviation of 0.70). Ratings range from 4.0 to 10.0, with the majority falling between 8.0 and 9.0.\n",
    "- <b> Flavor: </b>  Interpretation: The average flavor rating is around 8.62, with a moderate level of variability (standard deviation of 0.73). Ratings range from 1.0 to 10.0, with the majority falling between 8.0 and 9.0.\n",
    "- <b> Acid: </b> Interpretation: The average acidity rating is around 7.97, with a moderate level of variability (standard deviation of 0.71). Ratings range from 3.0 to 10.0, with the majority falling between 8.0 and 8.0\n",
    "- <b> Body: </b> Interpretation: The average body rating is around 8.16, with a relatively low level of variability (standard deviation of 0.63). Ratings range from 6.0 to 10.0, with the majority falling between 8.0 and 9.0.\n",
    "- <b> Interpretation: </b> The average aftertaste rating is around 7.97, with a moderate level of variability (standard deviation of 0.71). Ratings range from 3.0 to 10.0, with the majority falling between 8.0 and 8.0\n",
    "\n",
    "This is due to the fact that the ratings are over 60 which means that these are coffees are probably on the higher end of coffee ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fc6d4-a526-4e1a-afa6-7114720a7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d42a4-fdec-4bc1-acb4-bc061024ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "coffee_data_scaled =scaler.fit_transform(coffee_data_df_features[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097dfff-9882-4fa5-88a7-854301999f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store inertia values and the values of k\n",
    "inertia = []\n",
    "k_values = list(range(1, 11))\n",
    "\n",
    "# Append the value of the computed inertia from the KMeans model\n",
    "for k in k_values:\n",
    "    k_model = KMeans(n_clusters=k, n_init=10, random_state=1)\n",
    "    k_model.fit(coffee_data_scaled)\n",
    "    inertia.append(k_model.inertia_)\n",
    "\n",
    "# Plot the Elbow Curve\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d44b8-de17-44d4-928a-ec7a8c6660e9",
   "metadata": {},
   "source": [
    "# PCA Application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794642ec-8d35-4ee7-a036-9398af306d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality with PCA\n",
    "pca = PCA(n_components=5)\n",
    "coffee_data_pca = pca.fit_transform(coffee_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03813a1-af63-4bc9-89ab-aadfc22cfd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the PCA explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance ratio for each component\n",
    "print(\"Explained Variance Ratio for Each Component:\")\n",
    "print(explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d4f13-8cae-4653-9e58-d8c148b651ba",
   "metadata": {},
   "source": [
    "### Summary: \n",
    "- <b> Component 1 (60.95%): </b> This component explains a significant portion of the dataset's variance, suggesting that it captures the most critical patterns or features in the original data. It can be considered the most dominant factor in the reduced-dimensional representation.\n",
    "\n",
    "- <b> Component 2 (20.51%): </b> While not as influential as the first component, the second component still contributes substantially to the overall variance. It captures additional patterns that are orthogonal to those captured by the first component.\n",
    "\n",
    "- <b> Component 3 (11.98%): </b> This component contributes less to the overall variance but still captures unique patterns in the data that were not accounted for by the first two components.\n",
    "\n",
    "- <b> Component 4 (6.51%): </b> This component explains a smaller portion of the variance, capturing patterns that are less significant in the overall structure of the data.\n",
    "\n",
    "- <b> Component 5 (0.60%): </b> The fifth component explains a very small amount of the total variance. In some cases, such a component may be considered noise or might not contribute significantly to the understanding of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b9ce1-b4fe-4ff7-90c1-a216a47c416e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the cumulative explained variance\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "# Print the cumulative explained variance\n",
    "print(\"Cumulative Explained Variance:\")\n",
    "print(cumulative_explained_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098eb765-82c7-48d6-9e18-a1a3b6af97d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the cumulative explained variance\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance vs. Number of Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc042c-a30f-4d95-a1ba-59310053d58f",
   "metadata": {
    "tags": []
   },
   "source": [
    "This showed that the first three components capture approximately 93.44% (60.95% + 20.51% + 11.98%) of the total variance which is a generally satisfactory amount for a dataset this small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e788c09-3bc2-465f-a058-876083f9cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PCA DataFrame\n",
    "coffee_pca_df = pd.DataFrame(\n",
    "    coffee_data_pca,\n",
    "    columns=[\"aroma\", \"flavor\", \"acid\", \"body\", \"aftertaste\"]\n",
    ")\n",
    "\n",
    "# Review the PCA DataFrame\n",
    "coffee_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1194d-6ad6-48d5-bf20-02a0a77d45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store inertia values and the values of k\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# Append the value of the computed inertia from the `inertia_` attribute of the KMeans model instance\n",
    "for i in k:\n",
    "    k_model = KMeans(n_clusters=i, n_init=10, random_state=1)  # Explicitly set n_init\n",
    "    k_model.fit(coffee_pca_df)\n",
    "    inertia.append(k_model.inertia_)\n",
    "\n",
    "# Define a DataFrame to hold the values for k and the corresponding inertia\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61067d5a-07ff-42bd-9ad8-58da80eacb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Review the DataFrame\n",
    "print(\"PCA Elbow Curve DataFrame:\")\n",
    "print(df_elbow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddbbe72-927b-4856-b7a6-9c084a6cf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Elbow Curve\n",
    "df_elbow.hvplot.line(\n",
    "    x=\"k\", \n",
    "    y=\"inertia\", \n",
    "    title=\" PCA Elbow Curve\", \n",
    "    xticks=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c1bfd-4961-4d65-ab05-4b5a09d2d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a KMeans model\n",
    "kmeans_model = KMeans(n_clusters=3, random_state=42)\n",
    "coffee_data_df['coffee_segments'] = kmeans_model.fit_predict(coffee_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56383ba8-dd47-4bd7-a694-b19acb1b67e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model with 3 clusters\n",
    "model = KMeans(n_clusters=3, random_state=0, n_init =10)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(coffee_pca_df)\n",
    "\n",
    "# Make predictions\n",
    "k_3 = model.predict(coffee_pca_df)\n",
    "\n",
    "# Create a copy of the PCA DataFrame\n",
    "coffee_info_pca_predictions_df = coffee_pca_df.copy()\n",
    "\n",
    "# Add a class column with the labels\n",
    "coffee_info_pca_predictions_df[\"coffee_segments\"] = k_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166d727-f600-45f1-9ab4-42dab09f3185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a pair plot where scatter plots show relationships between feature components \n",
    "sns.pairplot(\n",
    "    coffee_info_pca_predictions_df,\n",
    "    hue='coffee_segments',  # color by clusters\n",
    "    palette='viridis',      # colormap\n",
    "    diag_kind='kde',         # use kernel density estimates on the diagonal\n",
    "    height=2.5\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ddcf7-e5f5-42d2-a17d-78e29abdcadc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the models\n",
    "joblib.dump(model, \"models/kmeans_model.joblib\")\n",
    "joblib.dump(pca, \"models/pca_model.joblib\")\n",
    "\n",
    "# Load the KMeans model\n",
    "loaded_model = joblib.load(\"models/kmeans_model.joblib\")\n",
    "loaded_pca = joblib.load(\"models/pca_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d35281c-a285-427c-bfdc-ff0f409bc5d7",
   "metadata": {},
   "source": [
    "## Encode target and include one-hot encoding into dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6cfbb-29c7-4318-9963-0393c6d74357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labelEncode the slug and create a feature array \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "# Label encode the 'slug' column and create a new column 'target'\n",
    "label_encoder = LabelEncoder()\n",
    "coffee_data_df['target'] = label_encoder.fit_transform(coffee_data_df['rating'])\n",
    "\n",
    "# Drop the original 'slug' column\n",
    "coffee_data_df.drop('rating', axis=1, inplace=True)\n",
    "coffee_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90201b59-0fd8-42af-9348-3e33d3267a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the target column the first column for ease access \n",
    "target_column = coffee_data_df['target']\n",
    "\n",
    "# Drop the 'target' column from the DataFrame\n",
    "coffee_data_df.drop('target', axis=1, inplace=True)\n",
    "\n",
    "# Insert the 'target' column as the first column\n",
    "coffee_data_df.insert(0, 'target', target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6cecb-e36c-40ff-be4b-1b5569c48235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create features and target\n",
    "coffee_test = coffee_data_df[['aroma','body','flavor','acid','aftertaste']]\n",
    "\n",
    "# # Remove null values  \n",
    "# coffee_data_df = coffee_data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94124ff3-2f24-451d-a478-cee57f6191cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming X is your DataFrame with columns 'aroma', 'body', 'flavor', 'acid', and 'aftertaste'\n",
    "categorical_columns = ['aroma', 'body', 'flavor', 'acid', 'aftertaste']\n",
    "\n",
    "# Use get_dummies to one-hot encode the categorical columns\n",
    "coffee_test_encoded = pd.get_dummies(coffee_test[categorical_columns], columns=categorical_columns, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea264919-df21-477f-a8d9-daf4d024a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the one-hot encoded columns to the original DataFrame\n",
    "coffee_test = pd.concat([coffee_test, coffee_test_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abbc62-2cf1-4bc6-b9a8-5e0959fb5c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coffee_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea628e82-c544-48f1-a177-1088e33bd63d",
   "metadata": {},
   "source": [
    "Generally a one-hot encoded dataframe would be able to give us user preference information. In this dataset, as it is being used as a recommender system and also there is no user input there was no y variable that we could conclude on to assess. Therefore the function test relied on the cosine_similarity function based on the user input.\n",
    "\n",
    "In future projects, user input and ratings would be generally great information to look for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7734ad9",
   "metadata": {},
   "source": [
    "## Attempt use of Vectorisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fill missing values in desc_1 column with an empty string\n",
    "coffee_data_df['desc_1'] = coffee_data_df['desc_1'].fillna('')\n",
    "\n",
    "# Convert desc_1 column to string type\n",
    "desc_1_text = coffee_data_df['desc_1'].astype(str)\n",
    "\n",
    "# Create a matrix for desc_1\n",
    "X_desc_1 = CountVectorizer().fit_transform(desc_1_text).toarray()\n",
    "\n",
    "print(\"Matrix for desc_1:\")\n",
    "print(X_desc_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd021ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(matrix, row_idx1, row_idx2):\n",
    "    cos_sim = cosine_similarity(matrix[row_idx1, :].reshape(1, -1), matrix[row_idx2, :].reshape(1, -1))[0, 0]\n",
    "    return cos_sim\n",
    "\n",
    "# Iterate through rows using iterrows\n",
    "for idx1, row1 in coffee_data_df.iterrows():\n",
    "    for idx2, row2 in coffee_data_df.iterrows():\n",
    "        if idx1 < idx2:  # Avoid comparing the same document and duplicates\n",
    "            cos_sim = calculate_cosine_similarity(X_desc_1, idx1, idx2)\n",
    "            print(f'Cosine Similarity between coffee_id {idx1 + 1} and coffee_id {idx2 + 1}: {cos_sim}')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_similar_items(cosine_similarity_matrix):\n",
    "    # Iterate through rows\n",
    "    for i in range(cosine_similarity_matrix.shape[0]):\n",
    "        # Sort cosine similarity values in descending order and get the top 5 indices\n",
    "        top5_indices = cosine_similarity_matrix[i].argsort()[:-6:-1]\n",
    "\n",
    "        # Print the results\n",
    "        print(f'Top 5 most similar items to Document {i + 1}:')\n",
    "        for j in top5_indices:\n",
    "            print(f'\\tDocument {j + 1} - Similarity: {cosine_similarity_matrix[i, j]}')\n",
    "            \n",
    "# Find top 5 most similar items for each document\n",
    "find_top_similar_items(cos_sim) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c6892-e18e-4c3f-9ee8-33e24795ed3f",
   "metadata": {},
   "source": [
    "# Testing function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e015a01-c9d9-4402-ab93-3f62e8c5285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "coffee_test = pd.DataFrame({\n",
    "    'aroma': np.random.randint(1, 11, 5),\n",
    "    'body': np.random.randint(1, 11, 5),\n",
    "    'flavor': np.random.randint(1, 11, 5),\n",
    "    'acid': np.random.randint(1, 11, 5),\n",
    "    'aftertaste': np.random.randint(1, 11, 5)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bbd52f-9de0-43be-bc6e-391a3a87730a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select a random coffee to test recommender system\n",
    "test_rec = coffee_test.sample(1, replace=False).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c010fff-75db-4c4f-960a-0a35e4af0e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recommender function \n",
    "def coffee_recommender(aroma, flavor, acid, body, aftertaste, model, pca, data, top_n=5):\n",
    "    # Transform user input using PCA\n",
    "    input_data = pca.transform([[aroma, flavor, acid, body, aftertaste]])[0]\n",
    "    input_array = input_data.reshape(1, -1)\n",
    "\n",
    "    # Make predictions using the loaded KMeans model\n",
    "    cluster_label = model.predict(input_array)[0]  # Fix input shape here\n",
    "\n",
    "    # Assign the cluster label to a new column\n",
    "    data['coffee_segments'] = model.predict(pca.transform(data[['aroma', 'flavor', 'acid', 'body', 'aftertaste']]))\n",
    "\n",
    "    # Filter data for the predicted cluster\n",
    "    recommended_coffees = data[data['coffee_segments'] == cluster_label]\n",
    "\n",
    "    # Calculate cosine similarity for each row\n",
    "    input_array = input_data.reshape(1, -1)\n",
    "    recommended_coffees['similarity_factor'] = recommended_coffees.apply(lambda row: cosine_similarity(input_array, row[['aroma', 'flavor', 'acid', 'body', 'aftertaste']].values.reshape(1, -1))[0][0], axis=1)\n",
    "\n",
    "    # Get the indices of the top N similar items\n",
    "    top_indices = recommended_coffees['similarity_factor'].nlargest(top_n).index.tolist()\n",
    "\n",
    "    return recommended_coffees.loc[top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd9459c-fd56-4c7c-bd8c-744784b6521f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to return the recommended coffee \n",
    "def recommend_coffees(test_rec, coffee_df, model, pca):\n",
    "    aroma, flavor, acid, body, aftertaste = test_rec['aroma'], test_rec['flavor'], test_rec['acid'], test_rec['body'], test_rec['aftertaste']\n",
    "    \n",
    "    recommended_coffees = coffee_recommender(aroma, flavor, acid, body, aftertaste, model, pca, coffee_df)\n",
    "\n",
    "    # Print only the top 5 recommendations\n",
    "    for i, (_, row) in enumerate(recommended_coffees[['name', 'roaster', 'roast', 'country_of_origin', 'desc_1', 'desc_2']].iterrows(), 1):\n",
    "        if i > 5:\n",
    "            break\n",
    "        print(f\"Recommendation #{i}\")\n",
    "        print(f\"Name: {row['name']}\")\n",
    "        print(f\"Roaster: {row['roaster']}\")\n",
    "        print(f\"Roast: {row['roast']}\")\n",
    "        print(f\"Country of Origin: {row['country_of_origin']}\")\n",
    "        print(f\"Description 1: {row['desc_1']}\")\n",
    "        print(f\"Description 2: {row['desc_2']}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Call the function with the test data\n",
    "for index, row in coffee_test.iterrows():\n",
    "    print(f\"\\nUser Input: {row.to_dict()}\")\n",
    "    recommend_coffees(row, coffee_data_df, loaded_model, loaded_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
